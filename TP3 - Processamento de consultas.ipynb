{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este projeto você irá implementar o processamento de consultas. Nela, você utilizará o índice para retornar uma coleção ordenada e avaliação de algumas consultas selecionadas. Para isso, vocês deverão implementar alguns métodos das seguintes classes.\n",
    "\n",
    "- `IndexPreComputedVals`: Em alguns modelos, há a necessidade de processar alguns valores para que, no momento da execução da consulta, seja retornado de forma mais rápida. Esta classe analisa o índice e armazena informações necessárias para o calculo de cada tipo de modelagem;\n",
    "- `RankingModel`: Classe abstrata para a criação dos modelos. Ele possui o método `get_ordered_docs` a ser implementado por suas subclasses;\n",
    "- `BooleanRankingModel` Classe que retorna um resultado de consulta por meio do [modelo booleano](https://docs.google.com/presentation/d/1V62ll_IXRrsp6TYUHjx_T4jIyIc1ZVJYoOSwsxObybE/edit?usp=sharing)\n",
    "- `VectorRankingModel`: Classe que retorna um resultado de consulta por meio do [modelo vetorial](https://docs.google.com/presentation/d/1jsD1MpLIl08OnWysDhjp7glc4_K0sH9sKUhRqI8lLLo/edit?usp=sharing)\n",
    "- `QueryRunner`: Classe principal encarregada de obter a consulta e retornar os resultados;\n",
    "\n",
    "\n",
    "Este trabalho depende do código do indice (pacote `index`). Assim, você deve adicioná-o apropriadamente para dar continuidade ao projeto. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelagem Booleana e Vetorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 1 - Modelagem Booleana**: A abordagem booleana neste trabalho é simplificada. O modelo recebe possui o atributo `operator` que é uma instancia do [Enum](https://docs.python.org/3.4/library/enum.html) Operator. Caso o operador seja AND, será feito a operacao de interseção entre todos os documentos contidos ocorrencias de palavras, caso contrario, sendo OR, será feito a união. Exemplo: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from index.structure import TermOccurrence\n",
    "map_ocorrencias = {\"saturno\":[TermOccurrence(1,1,1),\n",
    "                            TermOccurrence(3,1,1)],\n",
    "                     \"plutao\":[TermOccurrence(2,5,1),\n",
    "                               TermOccurrence(4,5,1)],\n",
    "                        \"terra\":[TermOccurrence(1,2,1),\n",
    "                            TermOccurrence(2,2,1),\n",
    "                            TermOccurrence(4,2,1),],\n",
    "                        \"venus\":[TermOccurrence(1,3,1),\n",
    "                                TermOccurrence(2,3,1),\n",
    "                                TermOccurrence(3,3,1),\n",
    "                                TermOccurrence(4,3,1)],\n",
    "                        \"marte\":[TermOccurrence(1,4,2),\n",
    "                            TermOccurrence(3,4,1),\n",
    "                            TermOccurrence(4,4,1),],\n",
    "\n",
    "                        \"mercurio\":[TermOccurrence(3,6,1)]          \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[( doc: 1 term_id:1 freq: 1), ( doc: 3 term_id:1 freq: 1)]\n",
      "[( doc: 2 term_id:5 freq: 1), ( doc: 4 term_id:5 freq: 1)]\n",
      "[( doc: 1 term_id:2 freq: 1), ( doc: 2 term_id:2 freq: 1), ( doc: 4 term_id:2 freq: 1)]\n",
      "[( doc: 1 term_id:3 freq: 1), ( doc: 2 term_id:3 freq: 1), ( doc: 3 term_id:3 freq: 1), ( doc: 4 term_id:3 freq: 1)]\n",
      "[( doc: 1 term_id:4 freq: 2), ( doc: 3 term_id:4 freq: 1), ( doc: 4 term_id:4 freq: 1)]\n",
      "[( doc: 3 term_id:6 freq: 1)]\n"
     ]
    }
   ],
   "source": [
    "for one, two in map_ocorrencias.items():\n",
    "    print(two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2, 3, 4}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{1,2,3}|{2,4}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A intereseção entre `saturno` e `venus` resultará nos documentos 1 e 3 e, a união, nos documentos 1, 2, 3 e 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta é uma forma bem simplificada para implementarmos o modelo booleano. Para isso, você deverá implementar os métodos `union_all` e `intersection_all` presentes na classe `BooleanRankingModel` no arquivo `ranking_models.py`. Esses métodos recebem como parâmetro um mapa com a lista de correncias de cada termo (similar a exemplificada acima)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.000s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!python -m query.tests.ranking_models RankingModelTest.test_boolean_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 2 - TF-IDF:** Agora, no mesmo arquivo, iremos finalizar a implementação do modelo Vetorial utilizando a classe `VectorRankingModel`. Nesta classe, primeiramente, você deverá implementar os [métodos estáticos](https://daniel-hasan.github.io/cefet-web-grad/classes/python2/) `tf`, `idf` e `tf_idf`. Sendo que $TF = 1+log_2(f_{ij})$ e $IDF_i = log_2(\\frac{N}{n_i})$ em que $f_{ij}$ é a frequência do termo $i$ no documento $j$, $N$ é o número de documentos e $n_i$ é o número de documentos que ocorrem o termo $i$. Abaixo, faça testes destes métodos: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF:1.0 IDF:1.0 n_i: 2 N: 4\n",
      "\n",
      ".\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Run Test OK\n"
     ]
    }
   ],
   "source": [
    "from query.ranking_models import VectorRankingModel as vrm\n",
    "\n",
    "num_documentos = 4\n",
    "num_doc_com_termo = 2\n",
    "term_freq = 1\n",
    "expected_tf_idf = 1\n",
    "tf_idf = vrm.tf_idf(num_documentos, term_freq, num_doc_com_termo)\n",
    "\n",
    "assert expected_tf_idf == tf_idf, f'TF-IDF deveria ser 1, porem o valor recebido foi: {tf_idf}'\n",
    "\n",
    "print('')\n",
    "print('.')\n",
    "print('----------------------------------------------------------------------')\n",
    "print('')\n",
    "print('Run Test OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 3 - PreComputedVals:** No modelo vetorial temos que calcular a norma de cada documento $d_j$. Esse calculo não pode ser feito durante o preprocessamento da consulta. Assim, na classe `IndexPreComputedVals` possui o atributo `document_norm` que é um dicionário que mapeia cada documnto $j$ à sua norma. Esse calculo é feito apenas uma vez ao iniciar o programa. \n",
    "\n",
    "Desta forma, você deverá terminar de implementar o método `precompute_vals` que percorre todo o índice e armazena a norma de cada documento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF:3.0 IDF:0.5849625007211562 n_i: 2 N: 3\n",
      "TF:1.0 IDF:0.5849625007211562 n_i: 2 N: 3\n",
      "TF:1.0 IDF:0.5849625007211562 n_i: 2 N: 3\n",
      "TF:1.0 IDF:0.5849625007211562 n_i: 2 N: 3\n",
      "TF:1.0 IDF:0.5849625007211562 n_i: 2 N: 3\n",
      "TF:1.0 IDF:1.5849625007211563 n_i: 1 N: 3\n",
      "TF:1.0 IDF:0.5849625007211562 n_i: 2 N: 3\n",
      "TF:1.0 IDF:1.5849625007211563 n_i: 1 N: 3\n",
      "TF:1.0 IDF:1.5849625007211563 n_i: 1 N: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.006s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!python -m query.tests.ranking_models RankingModelTest.test_precomputed_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 4 - Método `get_ordered_docs` da classe `VectorRankingModel`:** Usando os métodos implementados anteriormente você deverá ordenar os documentos contidos no mapa de ocorrencias `docs_occur_per_term` de acordo com a consulta `query` utilizando o modelo vetorial. O parametro `query` mapeia um termo presente na consulta, para a sua ocorrencia (objeto da classe `TermOcurrence`) na propria consulta. \n",
    "\n",
    "Para cada termo $t$ que ocorre na consulta, `docs_occur_per_term` mapeia cada termo com a lista de ocorrencias dele no índice. Veja abaixo um exemplo destes parametros usando a consulta `to be or not to be`.  Veja que, na consulta, `doc_id = None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {\"to\":TermOccurrence(None, 1, 2),\n",
    "         \"be\":TermOccurrence(None, 2, 2),\n",
    "          \"or\":TermOccurrence(None, 3, 1),\n",
    "          \"not\":TermOccurrence(None, 4, 1),}\n",
    "docs_occur_per_term = {\n",
    "                                    \"to\":[TermOccurrence(1, 1, 4),\n",
    "                                          TermOccurrence(2, 1, 1),],\n",
    "                                      \"be\":[TermOccurrence(1, 2, 1),TermOccurrence(2, 2, 1)],\n",
    "                                     \"or\":[TermOccurrence(2, 3, 1)],\n",
    "                                    \"not\":[TermOccurrence(3, 4, 1)],\n",
    "                                }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse exemplo, temos a consulta (representado pela variavel `query`) 'to to be be or not', ou seja, o `to` e o `be` ocorrendo duas vezes na consulta e, os demais termos, uma vez - a ordem não é definida no parametro. Em `docs_occcur_per_term` temos a ocorrencia desses termos nos documentos da coleção. \n",
    "\n",
    "Você deve executar o modelo vetorial para obter o resultado `documents_weight` que mapeia, para cada documento a similaridade entre ele e a consulta utilizando o modelo vetorial e a distancia do cosseno. Note que neste método você **não** pode navegar por todos os documentos da coleção pois, caso seja feito isso, o código de vocês iriam demorar muito caso sua coleção tiver milhões ou bilhões de documentos. Uma dica é usar o `documents_weight` para armazenar os valores intermediarios do somatorio de $w_{ij} \\times  w_{iq}$, tais variáveis são definidas nos [slides de modelagem vetorial](https://docs.google.com/presentation/d/1jsD1MpLIl08OnWysDhjp7glc4_K0sH9sKUhRqI8lLLo/edit?usp=sharing). \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse método retorna dois valores: (a) uma lista de ids de documentos ordenada de acordo com o modelo vetorial - use o método e um dicionário que mapeia, para cada documento, o seu peso. O método `rank_document_ids` será útil. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF:1.0 IDF:1.0 n_i: 2 N: 4\n",
      "TF:1.0 IDF:1.0 n_i: 2 N: 4\n",
      "TF:1.0 IDF:1.0 n_i: 2 N: 4\n",
      "TF:1.0 IDF:0.4150374992788437 n_i: 3 N: 4\n",
      "TF:1.0 IDF:0.4150374992788437 n_i: 3 N: 4\n",
      "TF:1.0 IDF:0.4150374992788437 n_i: 3 N: 4\n",
      "TF:1.0 IDF:0.4150374992788437 n_i: 3 N: 4\n",
      "TF:1.0 IDF:0.5849625007211562 n_i: 2 N: 3\n",
      "TF:3.0 IDF:0.5849625007211562 n_i: 2 N: 3\n",
      "TF:1.0 IDF:0.5849625007211562 n_i: 2 N: 3\n",
      "TF:1.0 IDF:0.5849625007211562 n_i: 2 N: 3\n",
      "TF:1.0 IDF:0.5849625007211562 n_i: 2 N: 3\n",
      "TF:1.0 IDF:0.5849625007211562 n_i: 2 N: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.003s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!python -m query.tests.ranking_models RankingModelTest.test_vector_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processamento da Consulta e Avaliação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora você irá fazer o processamento da consulta, informada pelo usuário, além de sua avaliação. A implementação do processamento de consultas será feito na classe `QueryRunner` do arquivo `processing.py`.\n",
    "\n",
    "**Requisito antes de começar:** o código que foi feito da indexação deve estar funcionando. Será utilizado a base de dados da Wikipédia. Você não deverá fazer a indexação toda quando iniciar o programa, ao invés disso, você deve persistir o indice todo em arquivo após a indexação. Usando FileIndex, como as ocorrencias já estão armazenadas em arquivo, você precisa armazenar apenas o conteúdo do `dic_index`. A [biblioteca json](https://docs.python.org/3/library/json.html) pode ajudar. Este índice será lido do arquivo apenas uma vez no início da execução do programa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Criação da coleção de referência:** Para o projeto realizaremos uma avaliação bem simples, com o único intuito de simularmos um processo real de avaliação. Para tanto, consideraremos como conjunto de consultas de teste apenas três consultas:\n",
    "'Irlanda'\n",
    "'Belo Horizonte' e \n",
    "'São Paulo'\n",
    "\n",
    "O conjunto de documentos de teste compreenderá todas as páginas da base de dados da Wikipédia PT-BR utilizadas no projeto.  Para cada consulta, disponibilizamos um arquivo (na pasta `relevant_docs`) com o id de documentos relevantes (separados por vírgula) para as consultas teste.\n",
    "\n",
    "Por exemplo, um documento $D$ será considerado relevante para a consulta 'Belo Horizonte' somente \n",
    "se o id de $D$ estiver no arquivo `belo_horizonte.dat`. Você irá armazenar o conteúdo desses arquivos em memória para diminuir o tempo de busca. Feito isso, a coleção de referência para as três consultas estará montada e pode-se realizar os cálculos de avaliação corretamente.\n",
    "\n",
    "**Como um artigo foi considerado relevante para uma determinada consulta?** A Wikipedia organiza seus artigos em diversas categorias. Assim, para considerarmos se um artigo da Wikipédia é relevante, utilizamos essas categorias. Assim, para os documentos relevantes para a consulta 'Irlanda' (Arquivo `irlanda.dat`), foram considerados relevantes artigos da seguintes categorias: \n",
    " \n",
    "- Irlanda\n",
    "- Economia da Irlanda\n",
    "- História da Irlanda\n",
    "- Cultura da Irlanda\n",
    "- Romancistas da Irlanda\n",
    "- Físicos da Irlanda\n",
    "- Reis da Irlanda\n",
    "- Lordes da Irlanda\n",
    "\n",
    "Categorias relevantes para a consulta 'Belo Horizonte' (Arquivo `belo_horizonte.dat`): \n",
    "\n",
    "- Bairros de Belo Horizonte\n",
    "- Bandas de Belo Horizonte\n",
    "- Belo Horizonte\n",
    "- Edifícios de Belo Horizonte\n",
    "- Metrô de Belo Horizonte\n",
    "- Naturais de Belo Horizonte\n",
    "- Prefeitos de Belo Horizonte\n",
    "- Vereadores de Belo Horizonte\n",
    "\n",
    "Categorias relevantes para a consulta 'São Paulo' (arquivo `sao_paulo.dat`):\n",
    "\n",
    "- Atrações turísticas da cidade de São Paulo\n",
    "- Áreas protegidas de São Paulo\n",
    "- Prefeitos de São Paulo\n",
    "- São Paulo\n",
    "- Turismo em São Paulo\n",
    "- Universidades de São Paulo\n",
    "- Rodovias de São Paulo\n",
    "- Museus da cidade de São Paulo\n",
    "- Governadores de São Paulo\n",
    "- Municípios de São Paulo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 5 - Leitura dos arquivos de relevâncias:** Você deverá implementar o método `get_relevance_per_query` que irá ler todos os arquivo da pasta `relevant_docs` e, com isso, retornar um mapeamento em que a chave é a string de consulta e o valor é o **conjunto** de ids de documentos. Veja um exemplo de retorno com as consultas `Bolívia`, `Brasil` e `Porto Seguro`: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_return = {\"Bolívia\":{1,3,5,6,233},\n",
    "            \"Brasil\":{2,4,5,3},\n",
    "           \"Porto Seguro\":{3,43,21,3,12,233}\n",
    "          }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faça um teste de execução abaixo: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O retorno de dic_relevance_docs é: {'belo_horizonte': {'110030', '1083', '136473', '35985', '43658', '49186', '38636', '125549', '484', '106575', '49772', '107302', '91853', '101043', '91593', '80198', '104137', '29241', '40226', '69168', '108604', '130173', '19588', '97000', '18111', '47967'}, 'irlanda': {'53004', '1196', '47185', '105145', '39049', '111966', '46441', '9918', '44259', '7765', '37935', '54836', '15393', '33833', '51716', '95773', '102888', '13256', '52998', '1034', '26276', '52995', '51778', '51779', '83228', '3765', '51714', '11953', '51786', '93223', '58189', '37632', '124818', '1393', '45577', '105348', '9955', '39300', '43872'}, 'sao_paulo': {'37053', '37240', '34829', '19963', '30119', '34950', '35079', '24089', '35183', '34850', '58105', '33739', '34926', '34852', '23990', '18769', '68791', '35217', '34872', '1291', '121946', '50674', '37258', '41906', '35164', '35202', '52388', '35069', '23988', '34857', '132760', '34911', '34908', '41971', '49745', '9277', '44043', '34914', '13726', '35216', '129465', '35195', '34985', '67967', '35056', '35156', '23420', '35231', '31882', '34982', '56690', '115341', '34918', '35158', '34978', '18285', '34963', '50702', '35000', '71562', '104847', '35205', '108677', '37252', '121025', '35100', '34896', '35098', '37297', '18482', '67061', '29477', '35087', '34921', '35115', '34892', '35031', '34824', '34832', '127538', '114091', '74190', '34786', '34882', '1752', '35054', '116539', '727', '34879', '34812', '60431', '34884', '98274', '34995', '35011', '34893', '34992', '100337', '135137', '35198', '18364', '9928', '34843', '64678', '37243', '49752', '34906', '62764', '123768', '26805', '37085', '25107', '47510', '34923', '35002', '35131', '35022', '30649', '42255', '30658', '34773', '29427', '35130', '132004', '22647', '35148', '35210', '16722', '110131', '35212', '106867', '64326', '35166', '35184', '42765', '34809', '35110', '34952', '103262', '34968', '34907', '35150', '29460', '34969', '27860', '34999', '110315', '41958', '34891', '22159', '30669', '29476', '35140', '105368', '34844', '114625', '34820', '34898', '35066', '34858', '35122', '115646', '34606', '52221', '54087', '120924', '34970', '37256', '123161', '24546', '34822', '34979', '35173', '34814', '71322', '35109', '53155', '12381', '23402', '35067', '128906', '17422', '37242', '34776', '35194', '34975', '31886', '15837', '35041', '58426', '47240', '34785', '35138', '34895', '78432', '35207', '76506', '34886', '62828', '130272', '820', '35162', '35029', '63702', '34962', '34972', '41944', '33267', '34777', '124032', '35058', '95286', '35213', '34800', '105372', '35027', '34863', '111495', '118365', '35020', '30402', '24088', '35239', '35046', '34837', '36655', '116543', '35224', '107278', '35223', '35165', '120284', '35117', '35004', '117843', '34849', '34981', '3546', '63775', '132679', '35233', '35102', '34955', '44027', '34902', '34779', '35095', '35052', '35182', '35149', '35227', '63617', '35055', '34862', '35144', '54428', '63593', '41964', '34831', '35177', '120719', '23983', '34794', '35145', '120839', '34840', '34943', '18489', '35038', '63613', '30640', '60430', '63586', '72497', '103736', '35160', '34983', '35073', '1324', '35241', '35089', '113999', '117875', '67685', '34868', '34937', '34836', '34871', '35155', '103003', '34813', '35225', '29459', '103495', '42582', '35214', '36238', '35215', '111222', '1084', '34971', '35114', '23441', '7687', '11664', '31880', '23505', '34787', '37247', '37600', '35170', '30654', '34770', '45081', '34900', '34928', '117951', '34699', '35141', '30016', '35124', '71920', '43939', '96931', '34919', '34935', '35077', '38535', '35059', '21504', '10792', '35168', '58490', '47221', '8170', '37282', '35875', '34815', '63776', '130537', '34798', '34991', '35186', '17703', '72332', '96945', '35132', '33850', '35007', '113733', '127303', '34778', '60377', '61190', '32738', '41967', '35230', '12218', '37241', '35189', '35021', '1719', '9744', '35061', '35074', '35181', '21467', '84257', '34998', '35174', '35006', '131865', '35070', '41955', '105369', '44033', '35024', '34958', '35204', '125486', '18143', '35235', '34861', '34847', '35047', '34803', '34987', '107841', '77762', '44596', '35113', '34965', '123706', '35167', '34830', '12383', '35139', '11478', '40127', '34825', '54205', '33643', '18411', '35218', '34885', '35119', '108256', '35012', '35151', '35043', '34869', '34939', '35034', '44836', '128145', '34653', '31202', '35125', '34930', '35086', '110028', '37244', '104490', '34876', '56310', '34894', '27897', '65568', '125876', '18305', '31888', '34934', '34931', '126579', '35036', '63584', '34903', '91915', '34841', '63637', '64908', '35143', '37056', '34784', '35101', '34933', '114888', '34888', '124692', '31879', '34915', '35049', '120283', '83535', '41961', '35229', '35197', '34873', '63827', '35093', '112599', '66592', '34627', '31889', '41948', '46533', '34986', '35240', '124267', '34880', '35023', '23412', '18515', '34890', '41761', '7847', '110916', '53269', '63715', '34865', '37255', '52391', '35134', '71254', '78269', '32573', '35112', '35161', '121580', '35201', '34945', '35030', '35123', '94770', '37087', '35206', '41942', '34897', '34851', '35222', '34874', '44001', '30653', '26173', '35196', '37249', '35001', '37265', '35193', '18299', '35175', '10558', '35092', '37261', '34806', '124892', '107604', '30641', '57810', '67965', '30667', '17661', '34808', '17768', '34932', '55965', '101163', '34953', '63123', '99800', '33530', '37274', '59093', '62759', '35099', '34984', '18312', '61403', '30652', '35039', '35083', '31890', '35221', '35135', '70457', '18307', '34940', '34819', '35048', '15814', '37054', '70209', '34613', '35064', '359', '67301', '96952', '35108', '34901', '23413', '35063', '35163', '35126', '96944', '130359', '35040', '34791', '34936', '41945', '34845', '34855', '35157', '9258', '35032', '34959', '35035', '35226', '35111', '35076', '35153', '64679', '34878', '35026', '34912', '35171', '35028', '34807', '35238', '36511', '23439', '34967', '53833', '34821', '37283', '35188', '34941', '128635', '24007', '34974', '45239', '125623', '32353', '16865', '34990', '10756'}}\n"
     ]
    }
   ],
   "source": [
    "from query.ranking_models import RankingModel\n",
    "from query.processing import QueryRunner\n",
    "from index.structure import FileIndex\n",
    "from index.indexer import Cleaner\n",
    "\n",
    "\n",
    "ranking_model = RankingModel()\n",
    "index = FileIndex()\n",
    "cleaner = Cleaner(stop_words_file=\"stopwords.txt\",\n",
    "                        language=\"portuguese\",\n",
    "                        perform_stop_words_removal=True,\n",
    "                        perform_accents_removal=True,\n",
    "                        perform_stemming=True)\n",
    "\n",
    "query_runner = QueryRunner(ranking_model, index, cleaner)\n",
    "dic_relevance_docs =  query_runner.get_relevance_per_query()\n",
    "print(f\"O retorno de dic_relevance_docs é: {dic_relevance_docs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 6 - count_top_n_relevant:** Um método que auxilirará vocês na avaliação é o método count_top_n_relevant da classe Query Runner.  Esse método calcula a quantidade de documentos relevantes nas top `n` posições da lista `lstResposta` que é a resposta a uma consulta - lista de ids de documentos. `lstResposta` será a lista de respostas ordenadas por um método de processamento de consulta (BM25, Modelo vetorial). Os ids de documentos relevantes estão no parametro `docRelevantes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m query.tests.processing ProcessingTest.test_count_top_n_relevant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 7 - processamento da consulta**: O método `get_query_term_occurence` a consulta da mesma forma que foi preprocessado o texto do documento (use a classe `Cleaner` para isso). Este método irá retonar a consulta em um dicionario em que chave é o termo que ocorreu e o valor é uma instancia da classe TermOccurrence (ver Atividade 4). O doc_id deverá ser sempre None. Caso o termo nao exista no indice, ele será desconsiderado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m query.tests.processing ProcessingTest.test_get_query_term_occurence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 8 - Recuperação dos termos da consulta no índice:** O método `get_occurrence_list_per_term` possui com parametro a lista de termos da consulta. Este método retorna um dicionario com a lista de ocorrencia no indice de cada termo passado como parametro. Caso o termo não exista, este termo possuirá uma lista vazia. Veja o exemplo na atividade 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m query.tests.processing ProcessingTest.test_get_occurence_list_per_term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 9 - processamento da consulta:** Este método recebe como parametro a consulta, os valores precomputado do índice e o dicionário de documentos relevantes (extraídos do método `get_relevance_per_query`) para retornar uma lista de IDs ordenados de acordo com a consulta utilizando o modelo de ranking e indice que são os atributos `index` e "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m query.tests.processing ProcessingTest.test_get_docs_term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 10: Método estático runQuery e criação da interface de caracteres - ou uso da interface gráfica/web:** Você deverá o método `runQuery` que utilizando o indice, valores precomputados e o dicionario de indices relevantes irá fazer:\n",
    "\n",
    "- Instanciar um objeto de uma subclasse de RankingModel, de acordo com o que foi solicitado pelo usuário\n",
    "- Preprocessar os termos da consulta\n",
    "- Obter no indice as ocorrencias de cada termo do indice\n",
    "- Utilize o método get_docs_term para obter a lista de documentos que responde esta consulta\n",
    "- Caso seja uma consulta que possua documentos relevantes assinalados, fazer a avaliação da precisão e revocação dos top 10, 20 e 50\n",
    "- Imprimir as top 10 respostas. \n",
    "\n",
    "Caso  opte por fazer uma interface de web, você não precisará de fazer este método em especifico  - nem o `main`, explicado a seguir - , mas, deverá possibilitar o usuário entre com uma consulta e retorne as top 10 respostas além de imprimir a precisão e revocação dos top 10, 20 e 50 das consultas que possuem documentos relevantes assinalados. \n",
    "            \n",
    "Caso opte por implementar uma interface de carcteres você deverá terminar de implementar o método `main` para solicitar ao usuário a consulta e execute-a abaixo. Caso deseje, ao inves disso, você pode também fazer uma interface gráfica. Para testar este método, você deverá usar o indice da Wikipedia, assim, ele deve ser lido no início do programa. Você tem a liberdade de alterar este método como bem entender, mas lembre-se que os valores precomputados devem ser executado uma vez só durante a execução do programa antes da solicitação das consultas para que a consulta não fique lenta. Além disso, você deve ler o arquivo do índice também apenas uma vez (não indexe a Wikipedia novamente e sim leia o arquivo do indice gravado em memória). Caso deseje, você pode modificar o IndexPreComputedVals para armazenar mais elementos precomputados que facilitariam a consulta (ou a exibição da mesma). \n",
    "\n",
    "\n",
    "Para melhorar a apresentação, o arquivo `titlePerDoc.dat` apresenta o título do artigo por id do mesmo. Além disso, você deverá fazer uma análise e acordo com o [guia de escrita do relatório](https://docs.google.com/document/d/1spwD-rzJi3xHV8p5cIAmjSHyVEzytChuBTnEDwBaDNQ/edit#heading=h.bsvivts5y2ld) considerando as [tarefas do Trabalho Prático 3](https://docs.google.com/document/d/1spwD-rzJi3xHV8p5cIAmjSHyVEzytChuBTnEDwBaDNQ/edit#heading=h.fh1qug6oeoe7).\n",
    "\n",
    "\n",
    "Caso opte por fazer uma interface web, deve estar claro, neste Jupyter, as instruções para que seja possível executa-la, inclusive, as suas dependencias. Para melhoria de organização, a parte de interface grafica ou web deve ser feita em outros arquivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "f64633889a19d683958c19bb3800619a62c64a4915e245407f18465ffe4255be"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
